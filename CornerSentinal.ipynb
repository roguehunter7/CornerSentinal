{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8Z6ljCuf6x"
      },
      "source": [
        "#Setup Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNpAOEv3Ii5G"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade ultralytics gdown onnx onnxruntime onnxsim ncnn filterpy scikit-image lap lapx fastapi kaleido lida python-multipart uvicorn tflite-support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7BTlJNn8OkX"
      },
      "source": [
        "#Github Clone and Setup Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XtlKPy-8REA"
      },
      "outputs": [],
      "source": [
        "!git clone --depth 1 https://github.com/roguehunter7/CornerSentinal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcdiSDM-9k7s"
      },
      "source": [
        "#Preparing Fresh Database from FiftyOne and Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY5CItG_9rDT"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade fiftyone ultralytics roboflow --no-cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P_TwMeV92H7"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import fiftyone.utils.random as four\n",
        "from ultralytics import YOLO\n",
        "\n",
        "EXPORT_DIR = \"/content/\"\n",
        "\n",
        "classes=[\"Ambulance\", \"Bus\", \"Car\", \"Motorcycle\", \"Taxi\", \"Truck\", \"Van\"]\n",
        "\n",
        "dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    splits=[\"train\"],\n",
        "    only_matching=True,\n",
        "    classes=classes,\n",
        "    label_types=\"detections\",\n",
        "    num_workers = 16,\n",
        "    shuffle=True,\n",
        "    max_samples = 5000,\n",
        "    cleanup=True\n",
        ")\n",
        "\n",
        "dataset.untag_samples(dataset.distinct(\"tags\"))\n",
        "\n",
        "four.random_split(\n",
        "    dataset,\n",
        "    {\"train\": 0.9, \"val\": 0.1}\n",
        ")\n",
        "\n",
        "def export_yolo_data(\n",
        "    samples,\n",
        "    export_dir,\n",
        "    classes,\n",
        "    label_field = \"ground_truth\",\n",
        "    split = None\n",
        "    ):\n",
        "\n",
        "    if type(split) == list:\n",
        "        splits = split\n",
        "        for split in splits:\n",
        "            export_yolo_data(\n",
        "                samples,\n",
        "                export_dir,\n",
        "                classes,\n",
        "                label_field,\n",
        "                split\n",
        "            )\n",
        "    else:\n",
        "        if split is None:\n",
        "            split_view = samples\n",
        "            split = \"val\"\n",
        "        else:\n",
        "            split_view = samples.match_tags(split)\n",
        "\n",
        "        split_view.export(\n",
        "            export_dir=export_dir,\n",
        "            dataset_type=fo.types.YOLOv5Dataset,\n",
        "            label_field=label_field,\n",
        "            classes=classes,\n",
        "            split=split\n",
        "        )\n",
        "\n",
        "export_yolo_data(\n",
        "    dataset,\n",
        "    \"vehicle_train\",\n",
        "    classes,\n",
        "    split = [\"train\", \"val\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILprbCeHQ4NP"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade git+https://github.com/ultralytics/ultralytics.git@main roboflow --no-cache\n",
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "RoboflowKey = userdata.get('RoboflowKey')\n",
        "rf = Roboflow(api_key=RoboflowKey)\n",
        "project = rf.workspace(\"main-project-dih2s\").project(\"cornersentinal\")\n",
        "dataset = project.version(12).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhK-Vch-QbYD"
      },
      "outputs": [],
      "source": [
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!sed -i '$d' {dataset.location}/data.yaml\n",
        "!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYU17FmK-HG_"
      },
      "outputs": [],
      "source": [
        "!mv -v /content/vehicle_train/images/train/* /content/CornerSentinal-12/train/images/\n",
        "!mv -v /content/vehicle_train/images/val/* /content/CornerSentinal-12/valid/images/\n",
        "!mv -v /content/vehicle_train/labels/train/* /content/CornerSentinal-12/train/labels/\n",
        "!mv -v /content/vehicle_train/labels/val/* /content/CornerSentinal-12/valid/labels/\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCQs8uJusOg"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqsO1tXBY8qk"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "!yolo task=detect mode=train model=yolov10n data=/content/CornerSentinal-12 epochs=100 plots=True imgsz=320 batch=-1 cache=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7axixdSau0Uq"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/detect1.zip /content/runs/detect/\n",
        "!cp -r /content/detect1.zip /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jx40mwDwIIt"
      },
      "outputs": [],
      "source": [
        "!ls /content/runs/detect/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFY53n3TwI89"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjtYPYuZwMJM"
      },
      "outputs": [],
      "source": [
        "Image(filename = '/content/runs/detect/train/confusion_matrix.png', width = 700)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGNSsXNswOVR"
      },
      "outputs": [],
      "source": [
        "Image(filename = r'/content/runs/detect/train/results.png', width = 700)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X7V_iKZwSvB"
      },
      "outputs": [],
      "source": [
        "Image(filename = r'/content/runs/detect/train/val_batch2_pred.jpg', width = 700)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_wjXvwRTZax"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0MNFEWlvUOY"
      },
      "source": [
        "#Copying Trained Model From Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIQWJ8BMaSIW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4lVRDtDvXu4"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/detect.zip /content/\n",
        "!unzip -q /content/detect.zip\n",
        "!mv -v /content/content/runs /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsiaV01b8YlG"
      },
      "outputs": [],
      "source": [
        "!yolo export model=/content/runs/detect/train/weights/best.pt format=onnx simplify=True dynamic=True int8=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg3TSxhXvhsu"
      },
      "source": [
        "#Benchmark Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS8ahLQ769yg"
      },
      "outputs": [],
      "source": [
        "!yolo benchmark model=/content/runs/detect/train/weights/best.pt data='/content/vehicle_train/dataset.yaml' imgsz=320 int8=True device=cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns-Suk_L_VxH"
      },
      "outputs": [],
      "source": [
        "!yolo export model=/content/runs/detect/train/weights/best.pt format=onnx simplify=True dynamic=True int8=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dyg5naA83Wf"
      },
      "source": [
        "#Program Video Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RB8HqTT-rh6"
      },
      "outputs": [],
      "source": [
        "%cd CornerSentinal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtXhuvV0-FlC"
      },
      "source": [
        "##leftside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP9mbPPL85vB"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import cv2\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov10n.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"test_images/leftside.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Constants for speed calculation\n",
        "VIDEO_FPS = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "FACTOR_KM = 3.6\n",
        "LATENCY_FPS = VIDEO_FPS / 2\n",
        "\n",
        "# Define the output video file path with MP4 format\n",
        "output_video_path = \"/content/CornerSentinal/test_images/leftside_out.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Use \"mp4v\" for H.264 compression\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, VIDEO_FPS, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def calculate_distance(p1, p2):\n",
        "    return np.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)\n",
        "\n",
        "# Function to calculate speed using Euclidean distance\n",
        "def calculate_speed(distances, factor_km, latency_fps):\n",
        "    if len(distances) <= 1:\n",
        "        return 0.0\n",
        "    average_speed = (np.mean(distances) * factor_km) / latency_fps * 10\n",
        "    return average_speed\n",
        "\n",
        "# Function to generate 9-bit binary code based on conditions\n",
        "def generate_binary_code(class_id, speed, is_stationary, is_wrong_side):\n",
        "    binary_code = ['0'] * 8\n",
        "\n",
        "    # Stationary bit\n",
        "    binary_code[0] = '1' if is_stationary else '0'\n",
        "\n",
        "    if class_id == 0:  # Ambulance\n",
        "        binary_code[2:5] = '100'\n",
        "    elif class_id in [2, 6, 4]:  # Car or Van or Taxi/Auto\n",
        "        binary_code[2:5] = '010'\n",
        "    elif class_id in [5, 1]:  # Bus or Truck\n",
        "        binary_code[2:5] = '011'\n",
        "    elif class_id == 3:  # Motorcycle\n",
        "        binary_code[2:5] = '001'\n",
        "\n",
        "    # Wrong side warning bit\n",
        "    binary_code[5] = '1' if is_wrong_side else '0'\n",
        "\n",
        "    # Replace speed section\n",
        "    if speed > 60:  # Overspeed Vehicle\n",
        "        binary_code[6:8] = '11'\n",
        "    elif 40 <= speed < 60:\n",
        "        binary_code[6:8] = '10'\n",
        "    elif 1.5 <= speed < 40:\n",
        "        binary_code[6:8] = '01'\n",
        "\n",
        "    return ''.join(binary_code)\n",
        "\n",
        "# Function to display warning message on the frame\n",
        "def display_warning_message(frame, binary_code):\n",
        "    warning_message = f\"Warning: {binary_code}\"\n",
        "    cv2.putText(frame, warning_message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "# Store track history for each vehicle\n",
        "track_history = defaultdict(list)\n",
        "stationary_timers = defaultdict(float)\n",
        "\n",
        "# Counter to keep track of frames\n",
        "frame_counter = 0\n",
        "\n",
        "# Placeholder for the previous frame and points for optical flow\n",
        "prev_frame = None\n",
        "prev_pts = None\n",
        "\n",
        "# Placeholder for the previous binary code\n",
        "prev_binary_code = None\n",
        "recv_binary_code = None\n",
        "prev_track_id = None\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret = cap.grab()\n",
        "    if ret:\n",
        "        success, frame = cap.retrieve()\n",
        "\n",
        "        # Check if YOLO inference should be performed on this frame\n",
        "        if frame_counter % 2 == 0:\n",
        "            results = model.track(frame, persist=True, tracker='bytetrack.yaml', imgsz=320, conf=0.25, int8=True)\n",
        "            annotated_frame = results[0].plot()\n",
        "\n",
        "            if results[0].boxes.id is not None:\n",
        "                boxes = results[0].boxes.xywh.cpu().numpy().astype(int)\n",
        "                class_id = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "                track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
        "\n",
        "                for i, box in enumerate(boxes):\n",
        "                    x, y, w, h = box\n",
        "                    xmin, ymin, xmax, ymax = x, y, x + w, y + h\n",
        "                    track = track_history[track_ids[i]]\n",
        "                    track.append((float(x + w / 2), float(y + h / 2)))\n",
        "\n",
        "                    if len(track) >= 2 and track[-2][1] < track[-1][1]:\n",
        "                        distances = [calculate_distance(track[j], track[j + 1]) for j in range(len(track) - 1)]\n",
        "                        speed = calculate_speed(distances, FACTOR_KM, LATENCY_FPS)\n",
        "                        is_stationary = speed < 1.0\n",
        "                        stationary_timers[track_ids[i]] = time.time() if not is_stationary else stationary_timers[\n",
        "                            track_ids[i]]\n",
        "\n",
        "                        if time.time() - stationary_timers[track_ids[i]] > 10.0:\n",
        "                            is_stationary = True\n",
        "                        is_wrong_side = False\n",
        "\n",
        "                        binary_code = generate_binary_code(class_id[i], speed, is_stationary, is_wrong_side)\n",
        "\n",
        "                        display_warning_message(annotated_frame, binary_code)\n",
        "                        cv2.putText(annotated_frame, f\"Speed: {speed:.2f} km/h\", (int(x), int(y) - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "                        roi = frame[int(y):int(y + h), int(x):int(x + w)]\n",
        "\n",
        "                        if prev_frame is not None and prev_pts is not None:\n",
        "                            prev_frame_resized = cv2.resize(prev_frame, (roi.shape[1], roi.shape[0]))\n",
        "                            flow = cv2.calcOpticalFlowPyrLK(prev_frame_resized, roi, prev_pts, None,\n",
        "                                                             winSize=(15, 15), maxLevel=2)\n",
        "                            flow_distances = np.sqrt(np.sum((prev_pts - flow[0]) ** 2, axis=2))\n",
        "\n",
        "                            good_pts = flow_distances > 0.5\n",
        "                            for j, is_good in enumerate(good_pts):\n",
        "                                if is_good:\n",
        "                                    x1, y1 = prev_pts[j].astype(int).ravel()\n",
        "                                    x2, y2 = (x + flow[0][j][0], y + flow[0][j][1]).astype(int)\n",
        "                                    cv2.line(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                            prev_frame = roi\n",
        "                            prev_pts = np.array([[(int(w / 2), int(h / 2))]], dtype=np.float32)\n",
        "\n",
        "    # Increment frame counter\n",
        "    frame_counter += 1\n",
        "    # Display the annotated frame\n",
        "    out.write(annotated_frame)  # Save the frame to the output video\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB3tEQwo9Cly"
      },
      "outputs": [],
      "source": [
        "!rm -rf '/content/leftside.mp4'\n",
        "import os\n",
        "# Set up NVIDIA GPU device for FFmpeg\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "# Convert leftside_out.mp4 to leftside.mp4 using GPU-accelerated FFmpeg\n",
        "os.system(f\"ffmpeg -hwaccel cuda -i '/content/CornerSentinal/test_images/leftside_out.mp4' -vcodec hevc_nvenc '/content/leftside.mp4'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTZFSwRq9Fy3"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/leftside.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz_XhGQF-BU_"
      },
      "source": [
        "##rightside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vQkGLDA96gN"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import cv2\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from lanedetector import *\n",
        "import numpy as np\n",
        "import threading\n",
        "from queue import Queue\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('train3/weights/best.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"test_images/rightside.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Constants for speed calculation\n",
        "VIDEO_FPS = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "FACTOR_KM = 3.6\n",
        "LATENCY_FPS = VIDEO_FPS / 2\n",
        "\n",
        "# Define the output video file path with MP4 format\n",
        "output_video_path = \"/content/CornerSentinal/test_images/leftside_out.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Use \"mp4v\" for H.264 compression\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, VIDEO_FPS, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "# Initialize lane detector\n",
        "ld = LineDrawerGUI(video_path)\n",
        "line_coords = ld.line_coords\n",
        "option_val = ld.option_val\n",
        "ld2 = LaneDetector(video_path, line_coords)\n",
        "ld2.calculate_all_points()\n",
        "points = ld2.points\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def calculate_distance(p1, p2):\n",
        "    return np.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)\n",
        "\n",
        "# Function to calculate speed using Euclidean distance\n",
        "def calculate_speed(distances, factor_km, latency_fps):\n",
        "    if len(distances) <= 1:\n",
        "        return 0.0\n",
        "    average_speed = (np.mean(distances) * factor_km) / latency_fps * 10\n",
        "    return average_speed\n",
        "\n",
        "# Function to generate 9-bit binary code based on conditions\n",
        "def generate_binary_code(class_id, speed, is_stationary, is_wrong_side):\n",
        "    binary_code = ['0'] * 8\n",
        "\n",
        "    # Stationary bit\n",
        "    binary_code[0] = '1' if is_stationary else '0'\n",
        "\n",
        "    if class_id == 0:  # Ambulance\n",
        "        binary_code[2:5] = '100'\n",
        "    elif class_id in [2, 6, 4]:  # Car or Van or Taxi/Auto\n",
        "        binary_code[2:5] = '010'\n",
        "    elif class_id in [5, 1]:  # Bus or Truck\n",
        "        binary_code[2:5] = '011'\n",
        "    elif class_id == 3:  # Motorcycle\n",
        "        binary_code[2:5] = '001'\n",
        "\n",
        "    # Wrong side warning bit\n",
        "    binary_code[5] = '1' if is_wrong_side else '0'\n",
        "\n",
        "    # Replace speed section\n",
        "    if speed > 60:  # Overspeed Vehicle\n",
        "        binary_code[6:8] = '11'\n",
        "    elif 40 <= speed < 60:\n",
        "        binary_code[6:8] = '10'\n",
        "    elif 1.5 <= speed < 40:\n",
        "        binary_code[6:8] = '01'\n",
        "\n",
        "    return ''.join(binary_code)\n",
        "\n",
        "# Function to display warning message on the frame\n",
        "def display_warning_message(frame, binary_code):\n",
        "    warning_message = f\"Warning: {binary_code}\"\n",
        "    cv2.putText(frame, warning_message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "# Store track history for each vehicle\n",
        "track_history = defaultdict(list)\n",
        "stationary_timers = defaultdict(float)\n",
        "\n",
        "# Counter to keep track of frames\n",
        "frame_counter = 0\n",
        "\n",
        "# Placeholder for the previous frame and points for optical flow\n",
        "prev_frame = None\n",
        "prev_pts = None\n",
        "\n",
        "# Placeholder for the previous binary code\n",
        "prev_binary_code = None\n",
        "recv_binary_code = None\n",
        "prev_track_id = None\n",
        "\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret = cap.grab()\n",
        "    if ret:\n",
        "        success, frame = cap.retrieve()\n",
        "\n",
        "        # Check if YOLO inference should be performed on this frame\n",
        "        if frame_counter % 2 == 0:\n",
        "            results = model.track(frame, persist=True, tracker='bytetrack.yaml', imgsz=320, conf=0.25, int8=True)\n",
        "            annotated_frame = results[0].plot()\n",
        "\n",
        "            if results[0].boxes.id is not None:\n",
        "                boxes = results[0].boxes.xywh.cpu().numpy().astype(int)\n",
        "                class_id = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "                track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
        "\n",
        "                for i, box in enumerate(boxes):\n",
        "                    x, y, w, h = box\n",
        "                    xmin, ymin, xmax, ymax = x, y, x + w, y + h\n",
        "                    track = track_history[track_ids[i]]\n",
        "                    track.append((float(x + w / 2), float(y + h / 2)))\n",
        "\n",
        "                    if len(track) >= 2 and track[-2][1] < track[-1][1]:\n",
        "                        distances = [calculate_distance(track[j], track[j + 1]) for j in range(len(track) - 1)]\n",
        "                        speed = calculate_speed(distances, FACTOR_KM, LATENCY_FPS)\n",
        "                        is_stationary = speed < 1.0\n",
        "                        stationary_timers[track_ids[i]] = time.time() if not is_stationary else stationary_timers[\n",
        "                            track_ids[i]]\n",
        "\n",
        "                        if time.time() - stationary_timers[track_ids[i]] > 10.0:\n",
        "                            is_stationary = True\n",
        "                        vehicle_pos = calculate_centroid(xmin, ymin, xmax, ymax)\n",
        "                        correct_lane = lane_detector(points, vehicle_pos, int(option_val))\n",
        "                        is_wrong_side = correct_lane != 1.0 and correct_lane != 0\n",
        "\n",
        "                        binary_code = generate_binary_code(class_id[i], speed, is_stationary, is_wrong_side)\n",
        "                        display_warning_message(annotated_frame, binary_code)\n",
        "                        cv2.putText(annotated_frame, f\"Speed: {speed:.2f} km/h\", (int(x), int(y) - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "                        roi = frame[int(y):int(y + h), int(x):int(x + w)]\n",
        "\n",
        "                        if prev_frame is not None and prev_pts is not None:\n",
        "                            prev_frame_resized = cv2.resize(prev_frame, (roi.shape[1], roi.shape[0]))\n",
        "                            flow = cv2.calcOpticalFlowPyrLK(prev_frame_resized, roi, prev_pts, None,\n",
        "                                                             winSize=(15, 15), maxLevel=2)\n",
        "                            flow_distances = np.sqrt(np.sum((prev_pts - flow[0]) ** 2, axis=2))\n",
        "\n",
        "                            good_pts = flow_distances > 0.5\n",
        "                            for j, is_good in enumerate(good_pts):\n",
        "                                if is_good:\n",
        "                                    x1, y1 = prev_pts[j].astype(int).ravel()\n",
        "                                    x2, y2 = (x + flow[0][j][0], y + flow[0][j][1]).astype(int)\n",
        "                                    cv2.line(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                            prev_frame = roi\n",
        "                            prev_pts = np.array([[(int(w / 2), int(h / 2))]], dtype=np.float32)\n",
        "\n",
        "    # Increment frame counter\n",
        "    frame_counter += 1\n",
        "    # Display the annotated frame\n",
        "    out.write(annotated_frame)  # Save the frame to the output video\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmkA-kBa9IDz"
      },
      "outputs": [],
      "source": [
        "!rm -rf '/content/rightside.mp4'\n",
        "\n",
        "import os\n",
        "\n",
        "# Set up NVIDIA GPU device for FFmpeg\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Convert hbfootage_out.mp4 to footage.mp4 using GPU-accelerated FFmpeg\n",
        "os.system(f\"ffmpeg -hwaccel cuda -i '/content/CornerSentinal/test_images/rightside_out.mp4' -vcodec hevc_nvenc '/content/rightside.mp4'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIjZEc2H9J-8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/rightside.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "R7BTlJNn8OkX",
        "W0MNFEWlvUOY",
        "Mg3TSxhXvhsu"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
